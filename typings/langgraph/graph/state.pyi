"""
This type stub file was generated by pyright.
"""

from collections import defaultdict
from collections.abc import Awaitable, Callable, Hashable, Sequence
from typing import Any, Generic, overload
from langchain_core.runnables import Runnable, RunnableConfig
from langgraph.cache.base import BaseCache
from langgraph.store.base import BaseStore
from typing_extensions import Self, Unpack
from langgraph._internal._typing import DeprecatedKwargs
from langgraph.channels.base import BaseChannel
from langgraph.graph._branch import BranchSpec
from langgraph.graph._node import StateNode, StateNodeSpec
from langgraph.managed.base import ManagedValueSpec
from langgraph.pregel import Pregel
from langgraph.types import All, CachePolicy, Checkpointer, RetryPolicy
from langgraph.typing import ContextT, InputT, NodeInputT, OutputT, StateT

__all__ = ("StateGraph", "CompiledStateGraph")
logger = ...
_CHANNEL_BRANCH_TO = ...
class StateGraph(Generic[StateT, ContextT, InputT, OutputT]):
    """A graph whose nodes communicate by reading and writing to a shared state.

    The signature of each node is `State -> Partial<State>`.

    Each state key can optionally be annotated with a reducer function that
    will be used to aggregate the values of that key received from multiple nodes.
    The signature of a reducer function is `(Value, Value) -> Value`.

    !!! warning

        `StateGraph` is a builder class and cannot be used directly for execution.
        You must first call `.compile()` to create an executable graph that supports
        methods like `invoke()`, `stream()`, `astream()`, and `ainvoke()`. See the
        `CompiledStateGraph` documentation for more details.

    Args:
        state_schema: The schema class that defines the state.
        context_schema: The schema class that defines the runtime context.

            Use this to expose immutable context data to your nodes, like `user_id`, `db_conn`, etc.
        input_schema: The schema class that defines the input to the graph.
        output_schema: The schema class that defines the output from the graph.

    !!! warning "`config_schema` Deprecated"
        The `config_schema` parameter is deprecated in v0.6.0 and support will be removed in v2.0.0.
        Please use `context_schema` instead to specify the schema for run-scoped context.

    Example:
        ```python
        from langchain_core.runnables import RunnableConfig
        from typing_extensions import Annotated, TypedDict
        from langgraph.checkpoint.memory import InMemorySaver
        from langgraph.graph import StateGraph
        from langgraph.runtime import Runtime


        def reducer(a: list, b: int | None) -> list:
            if b is not None:
                return a + [b]
            return a


        class State(TypedDict):
            x: Annotated[list, reducer]


        class Context(TypedDict):
            r: float


        graph = StateGraph(state_schema=State, context_schema=Context)


        def node(state: State, runtime: Runtime[Context]) -> dict:
            r = runtime.context.get("r", 1.0)
            x = state["x"][-1]
            next_value = x * r * (1 - x)
            return {"x": next_value}


        graph.add_node("A", node)
        graph.set_entry_point("A")
        graph.set_finish_point("A")
        compiled = graph.compile()

        step1 = compiled.invoke({"x": 0.5}, context={"r": 3.0})
        # {'x': [0.5, 0.75]}
        ```
    """
    edges: set[tuple[str, str]]
    nodes: dict[str, StateNodeSpec[Any, ContextT]]
    branches: defaultdict[str, dict[str, BranchSpec]]
    channels: dict[str, BaseChannel]
    managed: dict[str, ManagedValueSpec]
    schemas: dict[type[Any], dict[str, BaseChannel | ManagedValueSpec]]
    waiting_edges: set[tuple[tuple[str, ...], str]]
    compiled: bool
    state_schema: type[StateT]
    context_schema: type[ContextT] | None
    input_schema: type[InputT]
    output_schema: type[OutputT]
    def __init__(self, state_schema: type[StateT], context_schema: type[ContextT] | None = ..., *, input_schema: type[InputT] | None = ..., output_schema: type[OutputT] | None = ..., **kwargs: Unpack[DeprecatedKwargs]) -> None:
        ...
    
    @overload
    def add_node(self, node: StateNode[NodeInputT, ContextT], *, defer: bool = ..., metadata: dict[str, Any] | None = ..., input_schema: None = ..., retry_policy: RetryPolicy | Sequence[RetryPolicy] | None = ..., cache_policy: CachePolicy | None = ..., destinations: dict[str, str] | tuple[str, ...] | None = ..., **kwargs: Unpack[DeprecatedKwargs]) -> Self:
        """Add a new node to the `StateGraph`, input schema is inferred as the state schema.
        Will take the name of the function/runnable as the node name.
        """
        ...
    
    @overload
    def add_node(self, node: StateNode[NodeInputT, ContextT], *, defer: bool = ..., metadata: dict[str, Any] | None = ..., input_schema: type[NodeInputT], retry_policy: RetryPolicy | Sequence[RetryPolicy] | None = ..., cache_policy: CachePolicy | None = ..., destinations: dict[str, str] | tuple[str, ...] | None = ..., **kwargs: Unpack[DeprecatedKwargs]) -> Self:
        """Add a new node to the `StateGraph`, input schema is specified.
        Will take the name of the function/runnable as the node name.
        """
        ...
    
    @overload
    def add_node(self, node: str, action: StateNode[NodeInputT, ContextT], *, defer: bool = ..., metadata: dict[str, Any] | None = ..., input_schema: None = ..., retry_policy: RetryPolicy | Sequence[RetryPolicy] | None = ..., cache_policy: CachePolicy | None = ..., destinations: dict[str, str] | tuple[str, ...] | None = ..., **kwargs: Unpack[DeprecatedKwargs]) -> Self:
        """Add a new node to the `StateGraph`, input schema is inferred as the state schema."""
        ...
    
    @overload
    def add_node(self, node: str | StateNode[NodeInputT, ContextT], action: StateNode[NodeInputT, ContextT] | None = ..., *, defer: bool = ..., metadata: dict[str, Any] | None = ..., input_schema: type[NodeInputT], retry_policy: RetryPolicy | Sequence[RetryPolicy] | None = ..., cache_policy: CachePolicy | None = ..., destinations: dict[str, str] | tuple[str, ...] | None = ..., **kwargs: Unpack[DeprecatedKwargs]) -> Self:
        """Add a new node to the `StateGraph`, input schema is specified."""
        ...
    
    def add_node(self, node: str | StateNode[NodeInputT, ContextT], action: StateNode[NodeInputT, ContextT] | None = ..., *, defer: bool = ..., metadata: dict[str, Any] | None = ..., input_schema: type[NodeInputT] | None = ..., retry_policy: RetryPolicy | Sequence[RetryPolicy] | None = ..., cache_policy: CachePolicy | None = ..., destinations: dict[str, str] | tuple[str, ...] | None = ..., **kwargs: Unpack[DeprecatedKwargs]) -> Self:
        """Add a new node to the `StateGraph`.

        Args:
            node: The function or runnable this node will run.

                If a string is provided, it will be used as the node name, and action will be used as the function or runnable.
            action: The action associated with the node.
                Will be used as the node function or runnable if `node` is a string (node name).
            defer: Whether to defer the execution of the node until the run is about to end.
            metadata: The metadata associated with the node.
            input_schema: The input schema for the node. (Default: the graph's state schema)
            retry_policy: The retry policy for the node.

                If a sequence is provided, the first matching policy will be applied.
            cache_policy: The cache policy for the node.
            destinations: Destinations that indicate where a node can route to.

                Useful for edgeless graphs with nodes that return `Command` objects.

                If a `dict` is provided, the keys will be used as the target node names and the values will be used as the labels for the edges.

                If a `tuple` is provided, the values will be used as the target node names.

                !!! note

                    This is only used for graph rendering and doesn't have any effect on the graph execution.

        Example:
            ```python
            from typing_extensions import TypedDict

            from langchain_core.runnables import RunnableConfig
            from langgraph.graph import START, StateGraph


            class State(TypedDict):
                x: int


            def my_node(state: State, config: RunnableConfig) -> State:
                return {"x": state["x"] + 1}


            builder = StateGraph(State)
            builder.add_node(my_node)  # node name will be 'my_node'
            builder.add_edge(START, "my_node")
            graph = builder.compile()
            graph.invoke({"x": 1})
            # {'x': 2}
            ```

        Example: Customize the name:
            ```python
            builder = StateGraph(State)
            builder.add_node("my_fair_node", my_node)
            builder.add_edge(START, "my_fair_node")
            graph = builder.compile()
            graph.invoke({"x": 1})
            # {'x': 2}
            ```

        Returns:
            Self: The instance of the `StateGraph`, allowing for method chaining.
        """
        ...
    
    def add_edge(self, start_key: str | list[str], end_key: str) -> Self:
        """Add a directed edge from the start node (or list of start nodes) to the end node.

        When a single start node is provided, the graph will wait for that node to complete
        before executing the end node. When multiple start nodes are provided,
        the graph will wait for ALL of the start nodes to complete before executing the end node.

        Args:
            start_key: The key(s) of the start node(s) of the edge.
            end_key: The key of the end node of the edge.

        Raises:
            ValueError: If the start key is `'END'` or if the start key or end key is not present in the graph.

        Returns:
            Self: The instance of the `StateGraph`, allowing for method chaining.
        """
        ...
    
    def add_conditional_edges(self, source: str, path: Callable[..., Hashable | Sequence[Hashable]] | Callable[..., Awaitable[Hashable | Sequence[Hashable]]] | Runnable[Any, Hashable | Sequence[Hashable]], path_map: dict[Hashable, str] | list[str] | None = ...) -> Self:
        """Add a conditional edge from the starting node to any number of destination nodes.

        Args:
            source: The starting node. This conditional edge will run when
                exiting this node.
            path: The callable that determines the next node or nodes.

                If not specifying `path_map` it should return one or more nodes.

                If it returns `'END'`, the graph will stop execution.
            path_map: Optional mapping of paths to node names.

                If omitted the paths returned by `path` should be node names.

        Returns:
            Self: The instance of the graph, allowing for method chaining.

        !!! warning
            Without type hints on the `path` function's return value (e.g., `-> Literal["foo", "__end__"]:`)
            or a path_map, the graph visualization assumes the edge could transition to any node in the graph.

        """
        ...
    
    def add_sequence(self, nodes: Sequence[StateNode[NodeInputT, ContextT] | tuple[str, StateNode[NodeInputT, ContextT]]]) -> Self:
        """Add a sequence of nodes that will be executed in the provided order.

        Args:
            nodes: A sequence of `StateNode` (callables that accept a `state` arg) or `(name, StateNode)` tuples.

                If no names are provided, the name will be inferred from the node object (e.g. a `Runnable` or a `Callable` name).

                Each node will be executed in the order provided.

        Raises:
            ValueError: If the sequence is empty.
            ValueError: If the sequence contains duplicate node names.

        Returns:
            Self: The instance of the `StateGraph`, allowing for method chaining.
        """
        ...
    
    def set_entry_point(self, key: str) -> Self:
        """Specifies the first node to be called in the graph.

        Equivalent to calling `add_edge(START, key)`.

        Parameters:
            key (str): The key of the node to set as the entry point.

        Returns:
            Self: The instance of the graph, allowing for method chaining.
        """
        ...
    
    def set_conditional_entry_point(self, path: Callable[..., Hashable | Sequence[Hashable]] | Callable[..., Awaitable[Hashable | Sequence[Hashable]]] | Runnable[Any, Hashable | Sequence[Hashable]], path_map: dict[Hashable, str] | list[str] | None = ...) -> Self:
        """Sets a conditional entry point in the graph.

        Args:
            path: The callable that determines the next node or nodes.

                If not specifying `path_map` it should return one or more nodes.

                If it returns END, the graph will stop execution.
            path_map: Optional mapping of paths to node names.

                If omitted the paths returned by `path` should be node names.

        Returns:
            Self: The instance of the graph, allowing for method chaining.
        """
        ...
    
    def set_finish_point(self, key: str) -> Self:
        """Marks a node as a finish point of the graph.

        If the graph reaches this node, it will cease execution.

        Parameters:
            key (str): The key of the node to set as the finish point.

        Returns:
            Self: The instance of the graph, allowing for method chaining.
        """
        ...
    
    def validate(self, interrupt: Sequence[str] | None = ...) -> Self:
        ...
    
    def compile(self, checkpointer: Checkpointer = ..., *, cache: BaseCache | None = ..., store: BaseStore | None = ..., interrupt_before: All | list[str] | None = ..., interrupt_after: All | list[str] | None = ..., debug: bool = ..., name: str | None = ...) -> CompiledStateGraph[StateT, ContextT, InputT, OutputT]:
        """Compiles the `StateGraph` into a `CompiledStateGraph` object.

        The compiled graph implements the `Runnable` interface and can be invoked,
        streamed, batched, and run asynchronously.

        Args:
            checkpointer: A checkpoint saver object or flag.

                If provided, this `Checkpointer` serves as a fully versioned "short-term memory" for the graph,
                allowing it to be paused, resumed, and replayed from any point.

                If `None`, it may inherit the parent graph's checkpointer when used as a subgraph.

                If `False`, it will not use or inherit any checkpointer.
            interrupt_before: An optional list of node names to interrupt before.
            interrupt_after: An optional list of node names to interrupt after.
            debug: A flag indicating whether to enable debug mode.
            name: The name to use for the compiled graph.

        Returns:
            CompiledStateGraph: The compiled `StateGraph`.
        """
        ...
    


class CompiledStateGraph(Pregel[StateT, ContextT, InputT, OutputT], Generic[StateT, ContextT, InputT, OutputT]):
    builder: StateGraph[StateT, ContextT, InputT, OutputT]
    schema_to_mapper: dict[type[Any], Callable[[Any], Any] | None]
    def __init__(self, *, builder: StateGraph[StateT, ContextT, InputT, OutputT], schema_to_mapper: dict[type[Any], Callable[[Any], Any] | None], **kwargs: Any) -> None:
        ...
    
    def get_input_jsonschema(self, config: RunnableConfig | None = ...) -> dict[str, Any]:
        ...
    
    def get_output_jsonschema(self, config: RunnableConfig | None = ...) -> dict[str, Any]:
        ...
    
    def attach_node(self, key: str, node: StateNodeSpec[Any, ContextT] | None) -> None:
        ...
    
    def attach_edge(self, starts: str | Sequence[str], end: str) -> None:
        ...
    
    def attach_branch(self, start: str, name: str, branch: BranchSpec, *, with_reader: bool = ...) -> None:
        ...
    


